{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M5 Forecasting\n",
    "This competition (https://www.kaggle.com/c/m5-forecasting-accuracy/overview) aims to forecast Walmart sale forecast daily sales for the next 28 days. The data, covers stores in three US States (California, Texas, and Wisconsin) and includes item level, department, product categories, and store details. In addition, it has explanatory variables such as price, promotions, day of the week, and special events.\n",
    "\n",
    "This notebook uses M5 data to demonstrate the time series models:\n",
    "- seq2seq\n",
    "- wavenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Validation Series Partioning. We need to create 4 sub-segments of the data as the figure below:\n",
    "\n",
    "1. Train encoding period\n",
    "2. Train decoding period (train targets, 28 days)\n",
    "3. Validation encoding period\n",
    "4. Validation decoding period (validation targets, 28 days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig/web-traffic-train-validation-split.png\" width=\"700\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calendar shape: (1969, 14)\n",
      "Sell prices shape: (6841121, 4)\n",
      "Sales train shape: (30490, 1919)\n",
      "Submission shape: (60980, 29)\n",
      "ts_encode_norm shape torch.Size([30490, 365, 1])\n",
      " ts_decode_norm shape torch.Size([30490, 28, 1])\n",
      " ts_decode_true shape torch.Size([30490, 28, 1])\n",
      " ts_xdaysago_encode shape torch.Size([30490, 365, 2])\n",
      " ts_xdaysago_decode shape torch.Size([30490, 28, 2])\n",
      " cat_feat_encode shape torch.Size([30490, 365, 10])\n",
      " cat_feat_decode shape torch.Size([30490, 28, 10])\n",
      " fixed_feat_encode shape torch.Size([30490, 5])\n",
      " mean_x shape torch.Size([30490, 1, 1])\n",
      " std_x shape torch.Size([30490, 1, 1])\n",
      "\n",
      "ts_encode_norm shape torch.Size([30490, 365, 1])\n",
      " ts_decode_norm shape torch.Size([30490, 28, 1])\n",
      " ts_decode_true shape torch.Size([30490, 28, 1])\n",
      " ts_xdaysago_encode shape torch.Size([30490, 365, 2])\n",
      " ts_xdaysago_decode shape torch.Size([30490, 28, 2])\n",
      " cat_feat_encode shape torch.Size([30490, 365, 10])\n",
      " cat_feat_decode shape torch.Size([30490, 28, 10])\n",
      " fixed_feat_encode shape torch.Size([30490, 5])\n",
      " mean_x shape torch.Size([30490, 1, 1])\n",
      " std_x shape torch.Size([30490, 1, 1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from m5_dataloader import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "input_dir = '../data/M5'\n",
    "\n",
    "train_encode_decode_boundray = ('2015-03-01', '2016-02-28', '2016-02-29', '2016-03-27')\n",
    "val_encode_decode_boundray = ('2015-03-29', '2016-03-27', '2016-03-28', '2016-04-24')\n",
    "\n",
    "categorical_feat_l = ['week_number',\n",
    "                    'wday',\n",
    "                    'month',\n",
    "                    'event_name_1',\n",
    "                    'event_type_1',\n",
    "                    'event_name_2',\n",
    "                    'event_type_2',\n",
    "                    'snap_CA',\n",
    "                    'snap_TX',\n",
    "                    'snap_WI']\n",
    "\n",
    "\n",
    "fixed_feat_l=['item_id',\n",
    "            'dept_id',\n",
    "            'cat_id',\n",
    "            'store_id',\n",
    "            'state_id']\n",
    "\n",
    "xdaysago = [365, 91]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "calendar, sell_prices, sales_train, submission = read_data(input_dir)\n",
    "sales_train = process_sale_data(sales_train)\n",
    "processed_calendar = process_calendar(calendar)\n",
    "\n",
    "train_tuple = get_encode_decode_data(*train_encode_decode_boundray,\n",
    "                                     sales_train,\n",
    "                                     calendar,\n",
    "                                     processed_calendar,\n",
    "                                     categorical_feat_l,\n",
    "                                     xdaysago=xdaysago,\n",
    "                                     is_pred=False)\n",
    "\n",
    "val_tuple = get_encode_decode_data(*val_encode_decode_boundray,\n",
    "                                   sales_train,\n",
    "                                   calendar,\n",
    "                                   processed_calendar,\n",
    "                                   categorical_feat_l,\n",
    "                                   xdaysago=xdaysago,\n",
    "                                   is_pred=False)\n",
    "\n",
    "fixed_feat = get_fixed_feat(fixed_feat_l, sales_train)\n",
    "\n",
    "dataset_train = TSDataset(device, *train_tuple, fixed_feat)\n",
    "\n",
    "dataset_val = TSDataset(device, *val_tuple, fixed_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq import *\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=0,\n",
    "                              drop_last=True)\n",
    "\n",
    "dataloader_val = DataLoader(dataset_val,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=False,\n",
    "                            num_workers=0,\n",
    "                            drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Seq2Seq model\n",
    "the figure below show the input and output size of tensors and each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig/seq2seq_dimensions.png\" width=\"1200\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 1\n",
    "CONV1D_OUTPUT_DIM = 4\n",
    "CONV1D_KERNAL_SIZE = 5\n",
    "HID_DIM_ENCODE = 128\n",
    "HID_DIM_DECODE = 128\n",
    "N_LAYERS_RNN = 2\n",
    "DROPOUT_RNN = 0.5\n",
    "FC1_OUT_DIM = 64\n",
    "FC2_OUT_DIM = 16\n",
    "\n",
    "categorical_feat_emb_lookup = get_cat_feat_emb_para(categorical_feat_l, processed_calendar)\n",
    "fixed_feat_emb_lookup = get_fixed_feat_emb_para(fixed_feat_l, sales_train)\n",
    "\n",
    "model = Seq2Seq(\n",
    "    device,\n",
    "    HID_DIM_ENCODE,\n",
    "    HID_DIM_DECODE,\n",
    "    N_LAYERS_RNN, \n",
    "    DROPOUT_RNN,\n",
    "    categorical_feat_emb_lookup,\n",
    "    fixed_feat_emb_lookup,\n",
    "    xdaysago,\n",
    "    FC1_OUT_DIM,\n",
    "    FC2_OUT_DIM,\n",
    "    CONV1D_OUTPUT_DIM,\n",
    "    CONV1D_KERNAL_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n",
      "final_output size torch.Size([64, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d4995d4dadae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFORCH_TEACHING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Kaggle/pytorch-ts-forecasting/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, scheduler, criterion, clip, forch_teaching_rate)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/venv3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/venv3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from scheduler import OneCycleLR\n",
    "from train import train, evaluate\n",
    "from utils import RMSELoss\n",
    "import time\n",
    "\n",
    "LR = 0.001\n",
    "N_EPOCHS = 100\n",
    "CLIP = 2\n",
    "FORCH_TEACHING_RATE = 0\n",
    "EARLY_STOP_PATIENT = 10\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = OneCycleLR(optimizer, n_epochs=N_EPOCHS, n_batches=len(dataloader_train))\n",
    "criterion = RMSELoss()\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "train_loss_l = []\n",
    "valid_loss_l = []\n",
    "valid_loss_orig_l = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, dataloader_train, optimizer, scheduler, criterion, CLIP, FORCH_TEACHING_RATE)\n",
    "    valid_loss, valid_loss_orig = evaluate(model, dataloader_val, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_epoch_l.append(epoch)\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'seq2seq-fold{fold_nr}.pt')\n",
    "\n",
    "    train_loss_l.append(train_loss)\n",
    "    valid_loss_l.append(valid_loss)\n",
    "    valid_loss_orig_l.append(valid_loss_orig)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss_orig:.3f}')\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'\\tLR: {lr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
